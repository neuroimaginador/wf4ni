---
title: "Using `wf4ni` to Build a Volumetry Flow"
author: "Domingo López-Rodríguez"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
 %\VignetteIndexEntry{Using `wf4ni` to Build a Volumetry Flow}
 %\VignetteEngine{knitr::rmarkdown}
 %\VignetteEncoding{UTF-8}
---
  
```{r setup, include = FALSE}
  knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
  )
```
  
# Objective
  
# Requirements
  
## Packages
  
## Other Resources
  
# Segmentation
  
## Preprocessing
  
### Auxiliary Functions
  
```{r}
# - register to a template (MNI152 in case of structural imaging)
# Returns the transformation, as declared in the ANTsRCore package
register_to_template <- function(image, atlas_name) {
  
  require(ANTsRCore)
  require(ANTsR)
  require(extrantsr)
  
  image <- check_ants(image)
  
  template <- check_ants(get_atlas(atlas_name))
  
  transform <- antsRegistration(fixed = template,
                                moving = image,
                                typeofTransform = "AffineFast",
                                verbose = TRUE)
  
  return(transform)
  
} 

# Returns the image reoriented in the template space
get_img_in_template <- function(tx) {
  
  check_nifti(tx$warpedmovout)
  
}

# Returns the affine transformation
get_tx_to_template <- function(tx) {
  
  matrix(extrantsr::read_transformlist(tx$fwdtransforms)[[1]]$AffineTransform.float.3.3[1:9],
         nrow = 3, ncol = 3)
  
}

# Returns the scale parameter as the determinant of the affine trasnformation
get_scale_parameter <- function(M) {
  
  det(M)
  
}

# - bias field correction
bfc <- function(img) {
  
  image2 <- as.antsImage(img)
  
  image2 <- ANTsRCore::n4BiasFieldCorrection(img = image2, verbose = TRUE)
  
  return(ants2oro(image2, reference = img))
  
}

# - brain extraction
# Uses MALF technique with a "brain extraction" dataset
# Returns the brain mask
make_brain_extraction <- function(image, num_subjects = NULL) {
  
  problem <- "brain_extraction"
  problem_path <- problem %>% get_dataset()
  
  inputs <- list.files(file.path(problem_path, "inputs", "T1"), full.names = TRUE)
  outputs <- list.files(file.path(problem_path, "outputs"), full.names = TRUE)
  
  if (!is.null(num_subjects) && is.numeric(num_subjects)) {
    
    inputs <- inputs[seq(num_subjects)]
    outputs <- outputs[seq(num_subjects)]
    
  } else {
    
    num_subjects <- length(inputs)
    
  }
  
  system.time({
    
    L <- register_malf(image = oro2ants(image), 
                       template_files = inputs, 
                       label_files = outputs)
    
    templates <- L$templates
    labels <- L$labels
    
    rm(L)
    gc()
    
  })
  
  label_ids <- c(0, 1)
  
  # Let us normalize each template
  for (i in seq(num_subjects)) {
    
    templates[, , , i] <- templates[, , , i] / max(templates[, , , i])
    
  }
  
  # And the input image  
  image <- new_image / (max(image, na.rm = TRUE))
  
  res <- utils4ni::malf(input_image = image,
                             mask = NULL,
                             template4D = templates,
                             labels4D = labels, 
                             label_ids = label_ids, 
                             patch_size = 9, 
                             kernel_width = 3, 
                             max_iter = 10, 
                             ncores = parallel::detectCores())
  
  return(res)
  
}

```

### Flow code

```{r}
volumetry_flow <- NIflow$new(name = "volumetry", 
                             inputs = "T1")

volumetry_flow$add(what = register_to_template, 
                   inputs = "T1", 
                   output = "transformation", 
                   atlas_name = "MNI152_T1") 

volumetry_flow$add(what = get_img_in_template, 
                   inputs = "transformation", 
                   output = "T1_MNI")

volumetry_flow$add(what = get_tx_to_template, 
                   inputs = "transformation", 
                   output = "affine_transform")

volumetry_flow$add(what = get_scale_parameter, 
                   inputs = "affine_transform", 
                   output = "scale_parameter")

volumetry_flow$add(what = bfc, 
                   inputs = "T1_MNI", 
                   output = "T1_bfc")

volumetry_flow$add(what = make_brain_extraction, 
                   inputs = "T1_bfc", 
                   output = "brain_mask", 
                   num_subjects = 10)

volumetry_flow$add(what = function(A, B) {A * B}, 
                   inputs = c("T1_bfc", "brain_mask"), 
                   output = "betted")


```

## Processing
  
### Auxiliary Functions
  
```{r}
# - segmentation (GM, WM an CSF)
# Uses ANTsR's atropos to find a segmentation into GM, WM and CSF
# Returns the segmentation as a labelled image with labels 0 (background),
# 1 (CSF), 2 (GM) and 3 (WM)
get_segmentation <- function(img, kmask = NA) {
  
  q <- img %>% as.vector() %>% quantile(probs = c(0.01, 1))
  img[img < q[1]] <- q[1]
  img[img > q[2]] <- q[2]
  kmimg <- as.antsImage((img - q[1]) / (q[2] - q[1]))
  img <- as.antsImage(img)
  
  dim <- kmimg@dimension
  pixeltype <- kmimg@pixeltype
  
  if (is.na(kmask)) {
    
    kmask <- getMask(kmimg, 0.01, 1, cleanup = 2)
    
  } else {
    
    kmask <- as.antsImage(kmask)
    
  }
  
  mrf <- 0.1
  k <- 3
  
  kmask <- iMath(kmask, "FillHoles") %>% thresholdImage(1, 2)
  nhood <- paste(rep(1, dim), collapse = "x")
  mrf <- paste("[", mrf, ",", nhood, "]", sep = "")
  kmimg <- atropos(a = kmimg, m = mrf, 
                   c = "[5,0]", 
                   i = paste("kmeans[", 
                             k, "]", sep = ""), 
                   verbose = TRUE, x = kmask)
  
  kmimg$segmentation <- antsImageClone(kmimg$segmentation, 
                                       pixeltype)
  
  return(kmimg$segmentation %>% as.array())
  
}
```

### Flow code

```{r}
volumetry_flow$add(what = get_segmentation, 
                   inputs = "betted", 
                   output = "segmentation")

```


# Parcellation

## Auxiliary Functions

```{r}
# - parcellation
# Uses MALF technique with a previously labelled dataset
make_parcellation <- function(image, mask, num_subjects = NULL) {
  
  require(extrantsr)
  
  problem <- "parcellation"
  problem_path <- problem %>% get_dataset()
  
  inputs <- list.files(file.path(problem_path, "inputs", "T1"), full.names = TRUE)
  outputs <- list.files(file.path(problem_path, "outputs", "original"), full.names = TRUE)
  
  if (!is.null(num_subjects) && is.numeric(num_subjects)) {
    
    num_subjects <- min(c(num_subjects, length(inputs)))
    
    inputs <- inputs[seq(num_subjects)]
    outputs <- outputs[seq(num_subjects)]
    
  } else {
    
    num_subjects <- length(inputs)
    
  }
  
  # Only brain tissue
  image[mask == 0] <- 0
  image[image < 0] <- 0
  
  L <- register_malf(image = oro2ants(image), 
                     template_files = inputs, 
                     label_files = outputs,
                     typeofTransform = "SyN",
                     regIterations = c(20, 10, 0),
                     synMetric = "meansquares",
                     flowSigma = 1,
                     gradstep = 1.5) #SyN

  templates <- L$templates
  labels <- L$labels
  
  rm(L)
  gc()
  
  label_ids <- labels %>% as.vector() %>% unique() %>% sort()
  label_ids <- label_ids[-1]
  
  labels <- map_ids_cpp(image = labels,
                        remap_classes = list(source = label_ids, 
                                             target = seq_along(label_ids)))
  
  # Let us normalize each template
  for (i in seq(num_subjects)) {
    
    templates[, , , i] <- templates[, , , i] / max(templates[, , , i])
    
  }
  
  # mean_template <- sum_4d(templates) / dim(templates)[4]
  # new_image <- map_images(source = image, target = mean_template)
  
  # And the input image  
  image <- new_image / (max(image, na.rm = TRUE))
  
  # subcortical_ids <- c(0, seq_along(label_ids[label_ids < 1000]))
  # cortex_ids <- c(0, setdiff(seq_along(label_ids), subcortical_ids))
  
  R <- utils4ni::malf(input_image = image,
                      mask = mask,
                      template4D = templates,
                      labels4D = labels, 
                      label_ids = c(0, seq_along(label_ids)), 
                      patch_size = 11,##
                      stride = 5,
                      max_iter = 25, 
                      search_size = 7, 
                      max_random_neighbours = 5,
                      early_stopping = list(tol = 1.e-4),
                      kernel_width = 3,
                      kernel_sigma = 1, 
                      ncores = parallel::detectCores())
  
  rm(list = c("templates", "labels"))
  gc()
  
  res <- map_ids_cpp(image = R,
                     remap_classes = list(source = seq_along(label_ids),
                                          target = label_ids))
  
  res[res == 1] <- 0
  
  return(res)
  
}

```


## Flow code

```{r}
volumetry_flow$add(what = make_parcellation, 
                   inputs = c("T1_bfc", "brain_mask"), 
                   output = "parcellation",
                   num_subjects = 10)

```

# Quantification

## Auxiliary Functions

## Flow code

```{r}
volumetry_flow$add(what = count_by_ROI,
                   inputs = "brain_mask",
                   output = "brain_volume_mni")

volumetry_flow$add(what = function(A, B) {A * B}, 
                   inputs = c("brain_volume_mni", "scale_parameter"),
                   output = "brain_volume")

volumetry_flow$add(what = count_by_ROI,
                   inputs = "segmentation",
                   output = "basic_volumetry_mni")

volumetry_flow$add(what = function(A, B) {A * B}, 
                   inputs = c("basic_volumetry_mni", "scale_parameter"),
                   output = "basic_volumetry")

volumetry_flow$add(what = count_by_ROI,
                   inputs = "parcellation",
                   output = "final_volumetry_mni")

volumetry_flow$add(what = function(A, B) {A * B}, 
                   inputs = c("final_volumetry_mni", "scale_parameter"),
                   output = "final_volumetry")

```

# Final Flow

![Complete volumetry flow](img/volumetry.png)

# Example

## Code

```{r}
# Load data of the brain extraction dataset
problem <- "brain_extraction"
problem_path <- problem %>% get_dataset()

t1_dir <- file.path(problem_path, "inputs", "T1")
t1_files <- list.files(path = t1_dir, pattern = ".nii", full.names = TRUE)

res <- volumetry_flow$compute(what = c("T1_bfc", 
                                       "brain_mask",
                                       "segmentation",
                                       "parcellation",
                                       "brain_volume",
                                       "basic_volumetry",
                                       "final_volumetry"),
                              from = list(T1 = t1_files[1]))

```

## Results

```{r}
res$brain_volume
res$basic_volumetry
res$final_volumetry
```


## Images

```{r}
plot_overlay <- function(image, overlay, text = "") {
  
  label_ids <- overlay %>% as.vector() %>% unique() %>% sort()
  label_ids <- label_ids[-1]
  overlay <- utils4ni::map_ids_cpp(image = overlay,
                                   remap_classes = list(source = label_ids, 
                                                        target = seq_along(label_ids)))
  
  num_classes <- length(label_ids) + 1
  col.y <- scales::alpha(colour = scales::hue_pal()(num_classes), alpha = 0.45)
  
  if (num_classes == 4)
    col.y <- scales::alpha(colour = scales::viridis_pal()(num_classes), alpha = 0.3)
  
  ortho2(x = image, y = overlay, col.y = col.y, text = text)
  
}
```

```{r}
plot_overlay(image = res$T1_bfc,
             overlay = res$brain_mask,
             text = "Brain Mask")

plot_overlay(image = res$T1_bfc,
             overlay = res$segmentation,
             text = "Segmentation")

plot_overlay(image = res$T1_bfc,
             overlay = res$parcellation,
             text = "Parcellation")

```



# Availability
